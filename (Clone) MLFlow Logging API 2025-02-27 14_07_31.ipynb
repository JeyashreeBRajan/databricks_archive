{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "548bbec7-178e-4595-b542-c9ad10d391be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import savetxt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f0f867d-b0f7-46c1-a103-f4162116b9de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "db =load_diabetes()\n",
    "X = db.data\n",
    "Y = db.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af942b7b-19a7-4f4c-86f8-77260c35dda5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Number of Observation in X_train: \", len(X_train))\n",
    "print(\"Number of Observation in X_test: \", len(X_test))\n",
    "print(\"Number of Observation in y_train: \", len(y_train))\n",
    "print(\"Number of Observation in y_test: \", len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5c557a2-4cb6-468e-b020-fc6eec8ea417",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(mlflow.version.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1eb7bd43-f38a-48d9-9e37-70ae9b535bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Hyperparametes\n",
    "\n",
    "n_estimators = 100\n",
    "max_depth = 5\n",
    "max_features = 3\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "rf.fit(X_train, y_train)\n",
    "prediction = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "776852c1-4daa-43eb-bcc6-8924186f6c70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "With Autolog enabled, all model parameter, model score and the fitted model are automatically stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9aae977a-1ecd-4830-b090-543d7335ad15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Now we will log the model\n",
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #Hyperparametes\n",
    "    n_estimators = 100\n",
    "    max_depth = 5\n",
    "    max_features = 3\n",
    "\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "    rf.fit(X_train, y_train)\n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "#Now are new model is logged under MLFlow Logging API experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a1bd36aa-605c-4eb9-a620-2f2c3712ba68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Custom logging\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #Set model parameter\n",
    "    n_estimators= 100\n",
    "    max_depth = 5\n",
    "    max_features = 3\n",
    "\n",
    "    #Create and train model\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Use the model to make prediction on test data\n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "    #Log the model parameters for this run\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "\n",
    "    #Define a metric to evaluate a model \n",
    "    mse = mean_squared_error(y_test, prediction)\n",
    "\n",
    "    #Log the metric from this run\n",
    "    mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "\n",
    "    #Log the model created by this run\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    #Save the table of predicted value\n",
    "    savetxt(\"prediction.csv\", prediction, delimiter=\",\")\n",
    "\n",
    "    #Log the saved table as Artifact\n",
    "    mlflow.log_artifact(\"prediction.csv\")\n",
    "\n",
    "    #Convert the residuals to pandas dataframe for graphic capabilities\n",
    "    df=pd.DataFrame(data = prediction - y_test)\n",
    "\n",
    "    #Create plot of residuals\n",
    "    plt.plot(df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    #Save the plot as artifact\n",
    "    plt.savefig(\"residual.png\")\n",
    "    mlflow.log_artifact(\"residual.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f335f027-215f-40f7-8298-c9f9a69ca008",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e9e7b70-47bf-4e26-abbf-1ad4b7669250",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Instead of creating a model inside MLFLow Logging API Experiment, we can customize the location\n",
    "\n",
    "experiment_name = \"/Shared/diabetes_experiment/\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "#Copy paste above code\n",
    "#Custom logging\n",
    "\n",
    "with mlflow.start_run():\n",
    "    #Set model parameter\n",
    "    n_estimators= 100\n",
    "    max_depth = 5\n",
    "    max_features = 3\n",
    "\n",
    "    #Create and train model\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Use the model to make prediction on test data\n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "    #Log the model parameters for this run\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "\n",
    "    #Define a metric to evaluate a model \n",
    "    mse = mean_squared_error(y_test, prediction)\n",
    "\n",
    "    #Log the metric from this run\n",
    "    mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "\n",
    "    #Log the model created by this run\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    #Save the table of predicted value\n",
    "    savetxt(\"prediction.csv\", prediction, delimiter=\",\")\n",
    "\n",
    "    #Log the saved table as Artifact\n",
    "    mlflow.log_artifact(\"prediction.csv\")\n",
    "\n",
    "    #Convert the residuals to pandas dataframe for graphic capabilities\n",
    "    df=pd.DataFrame(data = prediction - y_test)\n",
    "\n",
    "    #Create plot of residuals\n",
    "    plt.plot(df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    #Save the plot as artifact\n",
    "    plt.savefig(\"residual.png\")\n",
    "    mlflow.log_artifact(\"residual.png\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fabbd7a3-d728-436d-8db9-52e86520b4bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Get experiment details\n",
    "import mlflow\n",
    "experiment_path =  \"/Shared/diabetes_experiment/\"\n",
    "experiment = mlflow.set_experiment(experiment_path)\n",
    "\n",
    "print(\"Experiment ID: \", experiment_name.experiment_id)\n",
    "print(\"Experiment Artifact Location: \", experiment_name.artifact_location)\n",
    "print(\"Tags {}\".format(experiment_name.tags))\n",
    "print(\"LifeCycle Stage\", experiment_name.lifecycle_stage)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a29a773a-96ad-449d-a3f7-8ff0b31b0fc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Method 3: By providing experiment_id in Start_run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "29ff5bca-ef22-4d09-bbe8-19b6a13fffeb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=1786477809851533):\n",
    "    #Set model parameter\n",
    "    n_estimators= 100\n",
    "    max_depth = 5\n",
    "    max_features = 3\n",
    "\n",
    "    #Create and train model\n",
    "    rf = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, max_features=max_features)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    #Use the model to make prediction on test data\n",
    "    prediction = rf.predict(X_test)\n",
    "\n",
    "    #Log the model parameters for this run\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_param(\"max_features\", max_features)\n",
    "\n",
    "    #Define a metric to evaluate a model \n",
    "    mse = mean_squared_error(y_test, prediction)\n",
    "\n",
    "    #Log the metric from this run\n",
    "    mlflow.log_metric(\"mean_squared_error\", mse)\n",
    "\n",
    "    #Log the model created by this run\n",
    "    mlflow.sklearn.log_model(rf, \"random-forest-model\")\n",
    "\n",
    "    #Save the table of predicted value\n",
    "    savetxt(\"prediction.csv\", prediction, delimiter=\",\")\n",
    "\n",
    "    #Log the saved table as Artifact\n",
    "    mlflow.log_artifact(\"prediction.csv\")\n",
    "\n",
    "    #Convert the residuals to pandas dataframe for graphic capabilities\n",
    "    df=pd.DataFrame(data = prediction - y_test)\n",
    "\n",
    "    #Create plot of residuals\n",
    "    plt.plot(df)\n",
    "    plt.xlabel(\"Observation\")\n",
    "    plt.ylabel(\"Residual\")\n",
    "    plt.title(\"Residual Plot\")\n",
    "\n",
    "    #Save the plot as artifact\n",
    "    plt.savefig(\"residual.png\")\n",
    "    mlflow.log_artifact(\"residual.png\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) MLFlow Logging API 2025-02-27 14:07:31",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
