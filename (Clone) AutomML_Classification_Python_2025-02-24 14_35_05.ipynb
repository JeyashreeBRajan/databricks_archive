{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bfa92fd3-c761-4111-a693-a77fa03ac73b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Lessons learnt\n",
    "1. View the csv files in Catalog-> Browse DBFS\n",
    "2. View Delata table in Catalog -> databricks_ml_ws -> default-> tables\n",
    "3. Remove .(dot) in file headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8e295d70-4600-48b5-a071-cf90e871a537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, StringType, StructType, StructField\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"age\", DoubleType(), True),\n",
    "    StructField(\"workclass\", StringType(), True),\n",
    "    StructField(\"fnlwgt\", DoubleType(), True),\n",
    "    StructField(\"education\", StringType(), True),\n",
    "    StructField(\"education_num\", DoubleType(), True),\n",
    "    StructField(\"marital_status\", StringType(), True),\n",
    "    StructField(\"occupation\", StringType(), True),\n",
    "    StructField(\"relationship\", StringType(), True),\n",
    "    StructField(\"race\", StringType(), True),\n",
    "    StructField(\"sex\", StringType(), True),\n",
    "    StructField(\"capital_gain\", DoubleType(), True),\n",
    "    StructField(\"capital_loss\", DoubleType(), True),\n",
    "    StructField(\"hours_per_week\", DoubleType(), True),\n",
    "    StructField(\"native_country\", StringType(), True),\n",
    "    StructField(\"income\", StringType(), True)\n",
    "])\n",
    "census_df = spark.read.csv(\"/FileStore/tables/Census_income_t.csv\",schema=schema)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b52dea7b-564e-45cd-bc3e-5449768eab06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "census_df.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f4b5409-ab6c-4dbc-8bb7-b4494df5eb0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = census_df.randomSplit([0.8, 0.2], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa98e53d-a7e7-49da-b94f-d62ffd09b62e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from databricks import automl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "debe34e3-646b-4839-9034-6fe6271f55ee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "summary = automl.classify(train_df, target_col=\"income\", timeout_minutes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4dae6c32-5ca2-4faa-9f79-51207c10f344",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Method 1 - Predict using Pandas Df\n",
    "\n",
    "model_uri = summary.best_trial.model_path\n",
    "\n",
    "import mlflow\n",
    "\n",
    "#Preparing test df\n",
    "test_p_df = test_df.toPandas()\n",
    "\n",
    "y_test = test_p_df[\"income\"]\n",
    "x_test = test_p_df.drop([\"income\"], axis=1)\n",
    "\n",
    "#Run inference using best model\n",
    "model= mlflow.pyfunc.load_model(model_uri)\n",
    "predict = model.predict(x_test)\n",
    "test_p_df[\"income_Predicted\"] = predict\n",
    "display(test_p_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "37ca8bff-4ab4-4a38-bcfa-028e4b01879a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Method 2: Predict using Spart user defined function\n",
    "\n",
    "import mlflow\n",
    "\n",
    "model_uri = f\"runs:/{summary.best_trial.mlflow_run_id}/model\"\n",
    "\n",
    "predict = mlflow.pyfunc.spark_udf(spark, model_uri=model_uri, result_type=\"String\")\n",
    "pred_df = test_df.withColumn(\"Income_Predicted\", predict(*test_df.drop(\"income\").columns))\n",
    "display(pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ea7144ec-0897-4c7c-81f3-bd5ee9f87992",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Evaluate the model\n",
    "\n",
    "import sklearn.metrics\n",
    "\n",
    "model = mlflow.sklearn.load_model(model_uri)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "(Clone) AutomML_Classification_Python_2025-02-24 14:35:05",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
